---
title: "Final Assignment"
linktitle: "Final"
date: "12/14/2020"
due_date: "2021-05-13"
due_time: "12:00pm"
output:
  blogdown::html_page:
    css: "/slides/css/additionalCols.css"
menu:
  assignment:
    parent: Assignments
    weight: 6
type: docs
weight: 6
editor_options: 
  chunk_output_type: console
---

## Data

For this assignment you will be using the following dataset, and it's corresponding data dictionary (where it explains what each variable means)

- [<i class="fas fa-file-csv"></i> `hcp-data-version2.csv`](/assignments/hcp-data-version2.csv)
- [<i class="fas fa-file-csv"></i> `hcp-data-dictionary.csv`](/assignments/hcp-data-dictionary.csv)

#### About the HCP Dataset

The Human Connectome Project (HCP) was a landmark study for cognitive neuroscience, headed by Wash U and the University of Minnesota. It is a large-scale multi-center project that enabled the study of individual differences in neural functioning that subserve higher-order cognitive functions (Van Essen et al., 2013). The HCP collected *a ton* of data on 1200 participants, including genetic, physiological, self-report, behavioral, and neuroimaging (structural MRI, resting state functional MRI, and task activation functional MRI). This makes it among the largest and richest publicly available cognitive neuroscience datasets in existence.

For the purposes of this class and this final project, I am providing you with an extremely pared down version of this dataset, with several changes associated with it:

- All of the subject IDs have been changed
- Some participants were randomly removed to ensure that it's different from the original
- Some of the values have been replaced with other values so as not to be able to backtrace anything

You should use the data dictionary for more information on each column. 

Each of the 4 primary sections is worth 5 points. This assignment is worth **20 points** total. 

:::note

- You MUST use a RNotebook for this assignment. You will turn in *both* your .Rmd and .html files
- You should write your code following the principles of open science and reproducibility. That is, you need to write your code in a way that other people can undersatnd and reproduce your code. 

:::

:::warning
I **_strongly_** suggest that you read through the entire assignment *before* starting. Good luck!
:::

## Part 1 -- Preparing Your Data

:::list
- Import your data
- Clean such that it is ready for any analyses you might run. How you do this is up to you. Keep in mind that your code needs to be reproducible, so it must be shown in your RMarkdown file.
:::

## Part 2 -- Describing Your Data

Pick 5 of the variables from the dataset that you find particularly interesting for the following section.

:::list
Your job is to explore each of these 5 variables individually (that is, you are *not* looking at the relationship between any of these variables). Here's what you need to do for ALL 5 VARIABLES:

- Make a figure showing if the variable is normally distributed 
- Report at least 1 measure of central tendency and 1 measure of variability. This needs to be shown as either a nicely formatted table or you can put these on their respective figures (in either the top or bottom corner of the figure). 

To accomplish this goal, you *must*:

- Make use of `ggplot2` (as opposed to `base R`)
- Use *either* a `for loop` or a `function` that you wrote. You don't need both -- one or the other is fine.

:::

## Part 3 -- Comparing Two Means

Pick a continous variable and a categorical variable that has 2 groups. You are going to run a $t$-test to see if there are any significant differences in the mean of your continuous variable across the two groups. You may use a categorical variable that already exists in the dataset, or you may choose to take a continuous variable and dichotomize it. You should go with whichever you find to be a more interesting research question. Run this test. (Note, you can do this via the model comparison approach from class or via another function we talked about in the first unit of the course)

However, being the savvy statistician in training that you are, you realize that everything becomes "significant" when the sample size is really large. As such, you decide to bootstrap a measure of effect size. 

Based on your $t$-test analysis, bootstrap Cohen's $d$:

$$ d = \frac{\bar{x_1} - \bar{x_2}}{SD_p}$$
where $SD_p$ is the pooled sample standard deviation. You can make the assumption that sample sizes for the groups are equal (even if they are just slightly off). To get the pooled standard deviation, please use the following formula:

$$ SD_p = \sqrt{\frac{SD_1^2 + SD_2^2}{2}} $$

where $SD_1$ is the standard deviation of group 1 and $SD_2$ is the standard deviation of the second group. 

:::list
To summarize:

- Run the $t$-test
- Bootstrap Cohen's $d$ (using between 100 and 1000 iterations; you can choose the exact number). **YOU MUST USE A `for loop` FOR THIS SECTION!** You should *not* be using any extra packages for this -- just a `for loop` (which does not require a package). 
- Plot all of your bootstrapped Cohen's $d$s in either a histogram or density plot. That is, you should wind up with a single plot that contains all the Cohen's $d$s from each iteration.
- Take the mean of all the $d$s that you get from the iterations to get your bootstrapped Cohen's $d$
- Write 3-5 sentences describing your findings. Is your bootstrapped Cohen's $d$ a small, medium, or large effect size? What does this say in comparison to the $t$-test that you ran at the beginning of this section? Which do you trust more? 

:::

## Part 4 -- Relationships Amongst Variables

The goal of this section is to examine the relationship between 2 continuous variables, and see how this relationship changes in the presence of a third variable. 

You must use 2 variables that are *different* from Part 3. Your 3rd added variable can be one that you used in Part 3 or a new one. 

:::list

- First, run a correlation between your variables. Plot this. 
- Next, write 1-2 sentences describing if you believe this correlation (hint: revisit the lecture for things to be on the lookout for!). Describe why you do or do not trust the correlation coefficient. 
- Next, run a regression. You'll need to choose which variable will be the predictor, and which will be the outcome. Your do *not* need to plot this because it will be identical to the plot you made earlier of the correlation. Print out the outcome of this regression.
- Now, run a second regression model that includes the third variable. Plot this. If your third variable is categorical, this is easy. If it's continuous, you have 2 options:

  - Create a new variable that categorizes your variable into 3 or more categories. 
  - Look up `simple slopes` for regression and plot the simple slopes. In real research, this is by far the preferred method. However, we didn't cover this in class and I don't expect you to go this route. The first option is much easier. 
  
- Make either a table or a figure that tests one of the assumptions of regression. 
- Finally, write 3-5 sentences describing your findings. Based on your regression model, the test of one of the assumptions, and your plots, what can you interpret?

:::


##### CONGRATULATIONS!

Once this is submitted, you will have officially completed the class. Thank you for a wonderful (albeit super strange) semester! You've all worked really hard, and hopefully you feel like you've gained a new, useful skill. You can always email me if you have `R` or stats related questions. Keep in touch and best of luck!

-Shelly

![](https://media.giphy.com/media/19tWtHKEnBEk3vUBHE/giphy.gif)

