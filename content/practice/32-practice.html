---
title: "Practice Set: Tidyverse"
linktitle: "Dplyr and Tidyr"
output:
  blogdown::html_page:
    toc: true
    css: "/slides/css/additionalCols.css"
menu:
  practice:
    parent: Tidyverse
    weight: 11
type: docs
weight: 11
editor_options: 
  chunk_output_type: console
shiny: true
---

  <link rel="stylesheet" href="/slides/css/additionalCols.css" type="text/css" />

<div id="TOC">
<ul>
<li><a href="#tidyverse" id="toc-tidyverse">Tidyverse</a>
<ul>
<li><a href="#dplyr" id="toc-dplyr">dplyr</a></li>
<li><a href="#tidyr" id="toc-tidyr">tidyr</a></li>
</ul></li>
</ul>
</div>

<div id="tidyverse" class="section level2">
<h2>Tidyverse</h2>
<p>Without data, there would be no science. Without <em>clean</em> data, there
would be no analysis! Just because researchers have data <strong>does not</strong>
mean they can simply throw it into a regression and be done with it.</p>
<p>In reality, researchers spend much more time cleaning and preparing
their data than actually analyzing it: up to <strong>80%</strong> of the time spent
on data analysis tasks dealt with simply cleaning data (Dasu &amp; Johnson,
2003)!</p>
<p>Evidently, data cleaning is vital to research, but it is not as
difficult as it may seem! Fortunately, the collection of R packages in
<strong>Tidyverse</strong> make data cleaning incredibly less arduous and
painstaking; therefore, learning how to work with Tidyverse will make
your life all the more simple.</p>
<div id="dplyr" class="section level3">
<h3>dplyr</h3>
<p>The first (and arguably most important) of Tidyverse’s core packages is
<strong>dplyr</strong>. Of this package, we will focus on the five functions arguably
most vital for data cleaning:</p>
<ul>
<li><strong>filter()</strong></li>
<li><strong>select()</strong></li>
<li><strong>mutate()</strong></li>
<li><strong>summarise()</strong></li>
<li><strong>group_by()</strong></li>
</ul>
<p>We will begin with using dplyr on the <strong>steam_hw</strong> dataset. The data
comes from researcher Hao Lin at Tianjin University of Technology (Lin,
2024). Broadly, their research revolves around relationships between Big
Five personality traits and online gaming behavior, primarily Steam
platform activity.</p>
<div id="loading-in-the-data" class="section level4">
<h4>Loading in the data</h4>
<p>When you load in the dataset, the first column (usually labeled <em>…1</em>
if using <code>read_csv()</code>) contains values indexing the row number, which is
redundant with the row names of the data frame that already show this.</p>
<p>I like to remove this column to reduce clutter, and we can do that by
using the <code>select()</code> function.</p>
<p><strong>Hint</strong></p>
<p>Remember from the lecture that <code>select()</code> can not only be used to choose
which columns you want to keep, but also ones you want to get rid of:</p>
</div>
<div id="filtering-the-data" class="section level4">
<h4>Filtering the data</h4>
<p>Since this data was collected from a Chinese institution, I may be
interested in looking at the gaming behavior of <em>only</em> Chinese
participants.</p>
<p>To make sure I am only making inferences on Chinese participants, we
would need to filter() participants who are only from China.</p>
<p>We can quickly view the contents of <em>only</em> the <strong>country</strong> column by
using the <code>select()</code> function.</p>
<pre class="r"><code>steam_hw |&gt;
  select(country) |&gt;
  print()</code></pre>
<pre><code>## # A tibble: 171 × 1
##    country
##    &lt;chr&gt;  
##  1 china  
##  2 china  
##  3 china  
##  4 china  
##  5 china  
##  6 china  
##  7 china  
##  8 china  
##  9 china  
## 10 china  
## # ℹ 161 more rows</code></pre>
<div class="puzzle">
<p><strong>You try!</strong></p>
<p>What is the code for viewing the age column?</p>
</div>
<iframe src="https://shelly-cooper.shinyapps.io/32-learnr-app2" width="100%" height="800" frameborder="0" style="border-radius: 12px; border: 1px solid #ccc;" scrolling="auto">
</iframe>
<p>We can see here that there are <strong>3</strong> participants not from China. I want
to remove them from the data set, and I can do that using <code>filter()</code>.</p>
<pre class="r"><code>steam_china_1 &lt;- steam_hw |&gt;
  filter(country == &quot;china&quot;)</code></pre>
<div class="puzzle">
<p><strong>You try!</strong></p>
<p>What if I wanted to have a data frame with only people from Guatemala? Store this as an object called <code>steam_guatemala</code>.</p>
</div>
<iframe src="https://shelly-cooper.shinyapps.io/32-learnr-app3" width="100%" height="800" frameborder="0" style="border-radius: 12px; border: 1px solid #ccc;" scrolling="auto">
</iframe>
<p>If we look at this new data frame, our number of participants (i.e.,
rows) dropped from <strong>171</strong> to <strong>149</strong>. This is much more than just 3
participants that we are removing.</p>
<p>What happened? Is there something wrong with the <code>filter()</code> function?</p>
<p>There are a couple ways we can tackle this, and they involve using
<em>logical operators</em>.</p>
<p>We could, instead, filter out the other countries that are <strong>not</strong>
China:</p>
<pre class="r"><code>steam_china_2 &lt;- steam_hw |&gt;
  filter(!(country == &quot;Afghanistan&quot; | country == &quot;Australia&quot; | country == &quot;Guatemala&quot;))</code></pre>
<p>There are a couple of things to notice with the above code chunk.</p>
<ol style="list-style-type: decimal">
<li><p>I used <strong>!</strong> with filter: the ! means <strong>“not”</strong>, so I am keeping the
observations that are <strong>not</strong> following the subsequent filter
specifications.</p></li>
<li><p>Because there are 3 different countries in the country column that I
am not interested in, I need to list these 3 in the <code>filter()</code>
function. For this to work, I used <strong>“|”</strong> which means “or”. So I
am only keeping participants who did not respond with Afghanistan or
Australia or Guatemala.</p></li>
</ol>
<p>This won’t be the most efficient way if there are more than 3 countries
you would have to specify in the <code>filter()</code> command.</p>
<div class="puzzle">
<p><strong>You try!</strong></p>
<p>What is another way to filter for participants from China
that takes this spelling difference into consideration? Call the output <code>steam_china</code>.</p>
<p><em>Hint: Remember the logical operators.</em></p>
</div>
<iframe src="https://shelly-cooper.shinyapps.io/32-learnr-app4" width="100%" height="800" frameborder="0" style="border-radius: 12px; border: 1px solid #ccc;" scrolling="auto">
</iframe>
<p>Regardless, we now have a data frame with 168 observations: 3 less than
the 171 we initially worked with, showing that we have now filtered the
correct number of participants.</p>
<div class="puzzle">
<p><strong>You try!</strong></p>
<ul>
<li><p>If I wanted to filter for participants that are both from China <em>and</em> female, how could I do this? Call the result <code>steam_china_female</code></p></li>
<li><p>What about males who are 18-25 years old? Call the result <code>steam_young_male</code></p></li>
</ul>
<p><em>Hint: Remember the logical operators.</em></p>
</div>
<iframe src="https://shelly-cooper.shinyapps.io/32-learnr-app1/" width="100%" height="800" frameborder="0" style="border-radius: 12px; border: 1px solid #ccc;" scrolling="auto">
</iframe>
</div>
<div id="personality-variables" class="section level4">
<h4>Personality variables</h4>
<p>One of the standard ways of assessing the Big Five personality traits is by using the BFI-2 inventory (John &amp; Soto, 2017), which contains 12 items per personality trait (12 items times 5 traits = 60 total items), with each item measured on a scale from 1 to 5 (1 = strongly disagree and 5 = strongly agree).</p>
<p>In case you are not familiar, the Big Five contains these traits:</p>
<ul>
<li>Extraversion</li>
<li>Agreeableness</li>
<li>Conscientiousness</li>
<li>Neuroticism</li>
<li>Openness</li>
</ul>
<p>Looking back at our data frame, we see that participants’ scores on each item corresponds to the columns labeled with a letter, representing the trait, a number, and another letter. Just looking at individual items won’t tell us, for example, how extraverted a participant is; instead, we need some variable that gives us a combined score of the relevant items to get a personality trait score.</p>
<p>A simple metric is to take the sum of numeric response from each item, so participants will have a combined score of how extraverted they are (e.g., 52 out of 60 possible).</p>
<p>So, let us make 5 new variables that will give us the sum of participant’s trait scores along each of the 5 personality traits.</p>
<p>To do so, we need to sum across the items that correspond to each trait, separately (e.g., all Extraversion items summed together, all Agreeableness items, etc.). To do this, we can use <code>across()</code> which will apply a function over multiple columns, and combine that with the selecting function <code>starts_with()</code>, which we can use to specify which columns we want to sum across for each of the new variables we will create.</p>
<p>These functions are all nested within the <code>mutate()</code> command, which will add these new columns to the data frame:</p>
<pre class="r"><code>china_sum_1 &lt;- steam_china |&gt;
  mutate(
    Extra_sum = sum(across(starts_with(&quot;E_&quot;)), na.rm = TRUE),
    Agre_sum = sum(across(starts_with(&quot;A_&quot;)), na.rm = TRUE),
    Cons_sum = sum(across(starts_with(&quot;C_&quot;)), na.rm = TRUE),
    Neuro_sum = sum(across(starts_with(&quot;N_&quot;)), na.rm = TRUE),
    Open_sum = sum(across(starts_with(&quot;O_&quot;)), na.rm = TRUE)
  )

kable(china_sum_1[c(1:10), c(1, 73:77)])</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">id</th>
<th align="right">Extra_sum</th>
<th align="right">Agre_sum</th>
<th align="right">Cons_sum</th>
<th align="right">Neuro_sum</th>
<th align="right">Open_sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">5789</td>
<td align="right">7200</td>
<td align="right">6614</td>
<td align="right">5709</td>
<td align="right">7127</td>
</tr>
</tbody>
</table>
<p>In this new data frame, we successfully summed across the proper items, but the sum we get is MUCH larger than we would expect, and it is the same for <em>every</em> participant. We want to get the sum for <em>each</em> participant, not the total across <em>all</em> participants.</p>
<p>To do this, we need to make use of the <code>group_by()</code> function:</p>
<pre class="r"><code>china_sum_2 &lt;- steam_china |&gt;
  group_by(id) |&gt;
  mutate(
    Extra_sum = sum(across(starts_with(&quot;E_&quot;)), na.rm = TRUE),
    Agre_sum = sum(across(starts_with(&quot;A_&quot;)), na.rm = TRUE),
    Cons_sum = sum(across(starts_with(&quot;C_&quot;)), na.rm = TRUE),
    Neuro_sum = sum(across(starts_with(&quot;N_&quot;)), na.rm = TRUE),
    Open_sum = sum(across(starts_with(&quot;O_&quot;)), na.rm = TRUE)
  ) |&gt;
  ungroup()

kable(china_sum_2[c(1:10), c(1, 73:77)])</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">id</th>
<th align="right">Extra_sum</th>
<th align="right">Agre_sum</th>
<th align="right">Cons_sum</th>
<th align="right">Neuro_sum</th>
<th align="right">Open_sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">52</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">15</td>
<td align="right">60</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">36</td>
<td align="right">38</td>
<td align="right">39</td>
<td align="right">33</td>
<td align="right">37</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">38</td>
<td align="right">44</td>
<td align="right">46</td>
<td align="right">33</td>
<td align="right">29</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">36</td>
<td align="right">46</td>
<td align="right">41</td>
<td align="right">34</td>
<td align="right">38</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">28</td>
<td align="right">46</td>
<td align="right">45</td>
<td align="right">32</td>
<td align="right">40</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">26</td>
<td align="right">32</td>
<td align="right">39</td>
<td align="right">36</td>
<td align="right">52</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">38</td>
<td align="right">41</td>
<td align="right">57</td>
<td align="right">26</td>
<td align="right">41</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">42</td>
<td align="right">40</td>
<td align="right">38</td>
<td align="right">35</td>
<td align="right">38</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">31</td>
<td align="right">45</td>
<td align="right">19</td>
<td align="right">47</td>
<td align="right">57</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">38</td>
<td align="right">41</td>
<td align="right">41</td>
<td align="right">42</td>
<td align="right">44</td>
</tr>
</tbody>
</table>
<p>By using <code>group_by()</code>, we are specifying that the <code>mutate()</code> command will occur for each participant, separately. The result is 5 different columns with sums that correspond with each participant’s item data.</p>
</div>
<div id="group-comparison" class="section level4">
<h4>Group comparison</h4>
<p>Now that we have some metric of participants’ personality scores, we can do some analysis!</p>
<p>Since we have a gender variable, I might be interested in looking at, potentially, personality differences that emerge between gender groups.</p>
<p>We can take a quick glance at such differences using <code>group_by()</code> and <code>summarise()</code>:</p>
<pre class="r"><code>china_sum_2 |&gt;
  group_by(gender) |&gt;
  summarise(
    Extra_avg = mean(Extra_sum, na.rm = TRUE),
    Agre_avg = mean(Agre_sum, na.rm = TRUE),
    Cons_avg = mean(Cons_sum, na.rm = TRUE),
    Neuro_avg = mean(Neuro_sum, na.rm = TRUE),
    Open_avg = mean(Open_sum, na.rm = TRUE)
  )</code></pre>
<pre><code>## # A tibble: 2 × 6
##   gender Extra_avg Agre_avg Cons_avg Neuro_avg Open_avg
##   &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 female      33.6     42.7     38.1      35.4     45.3
## 2 male        34.9     43.0     40.1      33.1     40.8</code></pre>
<p>Using <code>summarise()</code> across each of the personality trait sum columns we just made, after grouping by our gender variable, we get a 2x6 data frame of the average sum for each personality trait between male and female participants.</p>
<div class="puzzle">
<p><strong>You try!</strong></p>
<p>How could I get this get summary but looking across the different age
groups? Call the new columns:</p>
<ul>
<li>Extra_avg</li>
<li>Agre_avg</li>
<li>Cons_avg</li>
<li>Neuro_avg</li>
<li>Open_avg</li>
</ul>
<p><em>Hint: How do you deal with missing data?</em></p>
</div>
<iframe src="https://shelly-cooper.shinyapps.io/32-learnr-app5/" width="100%" height="800" frameborder="0" style="border-radius: 12px; border: 1px solid #ccc;" scrolling="auto">
</iframe>
<p>Notice, as well, that the shape of the data frame changed dramatically using <code>summarise()</code>.</p>
<div class="quiz">
<p><strong>Quick Quiz</strong></p>
</div>
<iframe src="https://shelly-cooper.shinyapps.io/32-learnr-quiz1/" width="100%" height="400" frameborder="0" style="border-radius: 12px; border: 1px solid #ccc;" scrolling="auto">
</iframe>
<p>There seems to be relatively no differences between the gender groups
for most of the personality sums, but one seems relatively large.</p>
<p>We can test formally test this using the statistical functions from the
previous chapter <a href="/lectures/09-lecture">Stats &amp; Plot</a>!</p>
<pre class="r"><code>fit_Open &lt;- lm(Open_sum ~ factor(gender), data = china_sum_2)

(summ_Open &lt;- summary(fit_Open))</code></pre>
<pre><code>## 
## Call:
## lm(formula = Open_sum ~ factor(gender), data = china_sum_2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -20.7944  -4.7944  -0.7944   5.7213  19.2056 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         45.2787     0.9949  45.509  &lt; 2e-16 ***
## factor(gender)male  -4.4843     1.2467  -3.597 0.000424 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.771 on 166 degrees of freedom
## Multiple R-squared:  0.07231,	Adjusted R-squared:  0.06672 
## F-statistic: 12.94 on 1 and 166 DF,  p-value: 0.0004244</code></pre>
<p>From the summary, we do, indeed, find that there is a significant
difference in average Openness between males and females.</p>
<p>And, for better visualization, we can plot this difference! As we learn
about data visualization, you can get plots that look like this:</p>
<pre class="r"><code>china_plot &lt;- as.data.frame(predict(fit_Open, interval = &quot;confidence&quot;))

china_plot$gender &lt;- china_sum_2$gender

china_plot |&gt;
  ggplot() +
  geom_bar(aes(x = gender, y = fit, fill = gender), 
           #stat and fun is used to plot the means of the predicted values
           stat = &quot;summary&quot;, fun = &quot;mean&quot;, width = 0.75, alpha = 0.5) +
  geom_errorbar(aes(x = gender, ymin = lwr, ymax = upr), width = 0.1, linewidth = 0.75) +
  #geom_point() is for adding in the individual data points
  geom_point(aes(x = factor(gender), y = fit, color = gender), 
             position = &quot;jitter&quot;, alpha = 0.5) +
  scale_x_discrete(labels = c(&quot;female&quot; = &quot;Female&quot;, &quot;male&quot; = &quot;Male&quot;)) +
  ylim(0, 50) + #changing the limits of the y-axis
  labs(
    title = &quot;Gender Differences in Openness&quot;,
    subtitle = &quot;(95% Confidence Intervals)&quot;,
    x = &quot;Gender&quot;,
    y = &quot;Predicted Openness (Sum)&quot;
  ) +
  theme_classic() +
  #the below code is all for editing the size and positioning of the titles and labels
  theme(plot.title = element_text(size = 14, hjust = 0.5, face = &quot;bold&quot;),
        plot.subtitle = element_text(size = 14, hjust = 0.5),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12, margin = margin(r = 10)),
        legend.position = &quot;none&quot;)</code></pre>
<p><img src="/practice/32-practice_files/figure-html/unnamed-chunk-11-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="tidyr" class="section level3">
<h3>tidyr</h3>
<p>Now, in utilizing functions from the <strong>tidyr</strong> package in Tidyverse, we
can make more complex transformations to the data frame to answer more
questions about our data.</p>
<p>For this, let’s focus on Neuroticism, the trait revolving around the
tendency to experience and regulate negative emotions. Neuroticism has
been found to be positively associated with Internet addiction (Kayiş et
al., 2016), and people high in Neuroticism tend to use social media to
find support (Tang et al., 2016).</p>
<p>So, we can hypothesize that Neuroticism will be positively associated
with having more online, Steam friends. I ran the code, and it is!</p>
<div id="creating-composite-scores" class="section level4">
<h4>Creating composite scores</h4>
<p>However, while using the sum of personality items to make a trait score
is a simple and intuitive metric, that is not what is typically used by
personality researchers. Instead, we use <em>composite scores</em> to make
trait scores, which is the <strong>average</strong> score across the item responses.</p>
<p>In addition, the 12 items that correspond to each of the 5 personality
traits also belong to different facets: sub-domains within each trait.
The BFI-2 measures 3 facets per personality trait (which can be seen by
the lower-case letter at the end of each item name), with 4 items for
each trait tapping into each related facet. For Neuroticism, <em>Anxiety</em>,
<em>Depression</em>, and <em>Emotional Volatility</em> are the different facets.</p>
<p>To look at all of these different constructs, we need to create
composite scores for each, and we can do this using <strong>pivot_longer()</strong>.</p>
<p>First, let’s look at how our <em>wide</em> data frame looks:</p>
<pre class="r"><code>print(china_sum_2[1:10, c(1, 8, 13, 18, 23)])</code></pre>
<pre><code>## # A tibble: 10 × 5
##       id N_1_a N_2_d N_3_e N_4_a
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1     1     1     1     2
##  2     2     2     2     3     4
##  3     3     3     2     3     3
##  4     4     3     2     3     3
##  5     5     4     3     2     5
##  6     6     4     3     3     2
##  7     7     2     2     2     4
##  8     8     3     2     1     4
##  9     9     4     4     3     3
## 10    10     3     2     4     4</code></pre>
<p>Now, let’s see what <code>pivot_longer()</code> does, making a data frame with only
our Neuroticism items using <code>select()</code>.</p>
<pre class="r"><code>#remember to also include our grouping variable &quot;id&quot;
neuro_long &lt;- china_sum_2 |&gt;
  select(id, starts_with(&quot;N_&quot;)) |&gt;
  pivot_longer(
    cols = -id,
    names_to = &quot;item&quot;,
    values_to = &quot;score&quot;
  )

print(neuro_long[1:20, ])</code></pre>
<pre><code>## # A tibble: 20 × 3
##       id item   score
##    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;
##  1     1 N_1_a      1
##  2     1 N_2_d      1
##  3     1 N_3_e      1
##  4     1 N_4_a      2
##  5     1 N_5_d      1
##  6     1 N_6_e      1
##  7     1 N_7_a      2
##  8     1 N_8_d      1
##  9     1 N_9_e      1
## 10     1 N_10_a     2
## 11     1 N_11_d     1
## 12     1 N_12_e     1
## 13     2 N_1_a      2
## 14     2 N_2_d      2
## 15     2 N_3_e      3
## 16     2 N_4_a      4
## 17     2 N_5_d      3
## 18     2 N_6_e      3
## 19     2 N_7_a      2
## 20     2 N_8_d      3</code></pre>
<p>Now we have a data frame with 2,016 observations, and the data frame
looks A LOT different!</p>
<p>To get facet scores, R needs to know which items belong to which facet
of Neuroticism. We, therefore, need to separate the ending letter from
each item into another column using another tidyr function,
<code>separate()</code>:</p>
<pre class="r"><code>facet_long_1 &lt;- neuro_long |&gt;
  separate(col = item,
           into = c(&quot;item&quot;, &quot;facet&quot;))</code></pre>
<pre><code>## Warning: Expected 2 pieces. Additional pieces discarded in 2016 rows [1, 2, 3, 4, 5, 6,
## 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].</code></pre>
<pre class="r"><code>print(facet_long_1[1:20, ])</code></pre>
<pre><code>## # A tibble: 20 × 4
##       id item  facet score
##    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;
##  1     1 N     1         1
##  2     1 N     2         1
##  3     1 N     3         1
##  4     1 N     4         2
##  5     1 N     5         1
##  6     1 N     6         1
##  7     1 N     7         2
##  8     1 N     8         1
##  9     1 N     9         1
## 10     1 N     10        2
## 11     1 N     11        1
## 12     1 N     12        1
## 13     2 N     1         2
## 14     2 N     2         2
## 15     2 N     3         3
## 16     2 N     4         4
## 17     2 N     5         3
## 18     2 N     6         3
## 19     2 N     7         2
## 20     2 N     8         3</code></pre>
<p>When we do <code>separate()</code> here, however, we lose some information, and R
gives us a warning telling us that this happened. Why is this
happening?</p>
<p>To prevent this, we will need to use <code>separate()</code> to split them into three
columns first, and then we can use <code>unite()</code> to join the trait and
item number values back together:</p>
<pre class="r"><code>facet_long_2 &lt;- neuro_long |&gt;
  separate(col = item,
           into = c(&quot;trait&quot;, &quot;item_number&quot;, &quot;facet&quot;)) |&gt;
  unite(col = &quot;item&quot;,
        trait, item_number,
        sep = &quot;_&quot;)

print(facet_long_2[1:20, ])</code></pre>
<pre><code>## # A tibble: 20 × 4
##       id item  facet score
##    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;
##  1     1 N_1   a         1
##  2     1 N_2   d         1
##  3     1 N_3   e         1
##  4     1 N_4   a         2
##  5     1 N_5   d         1
##  6     1 N_6   e         1
##  7     1 N_7   a         2
##  8     1 N_8   d         1
##  9     1 N_9   e         1
## 10     1 N_10  a         2
## 11     1 N_11  d         1
## 12     1 N_12  e         1
## 13     2 N_1   a         2
## 14     2 N_2   d         2
## 15     2 N_3   e         3
## 16     2 N_4   a         4
## 17     2 N_5   d         3
## 18     2 N_6   e         3
## 19     2 N_7   a         2
## 20     2 N_8   d         3</code></pre>
<p>Now, we can explicitly tell R which items belong to which facet of
Neuroticism, and we will use this variable to calculate facet-level
composite scores.</p>
<div class="puzzle">
<p><strong>You try!</strong></p>
<p>We want each participant to have 3 composite (average)
scores, one for each facet.</p>
<ul>
<li>What will we need to include in <code>group_by()</code> to do this?</li>
<li>What operation within <code>mutate()</code> will we use to make the composites?</li>
<li>Show the first 10 rows and all of the columns</li>
</ul>
<p><em>Hint: Remember when we used <code>group_by(id)</code> to get the correct column of
personality score sums, per person.</em></p>
</div>
<iframe src="https://shelly-cooper.shinyapps.io/32-learnr-app6/" width="100%" height="800" frameborder="0" style="border-radius: 12px; border: 1px solid #ccc;" scrolling="auto">
</iframe>
<p>By using <code>group_by(id, facet)</code>, we group by both of these variables to get
a composite score of each facet that within each participant’s own data.</p>
<p>We are not done, however, as there is some unnecessary repetition going
on in the facet_comp variable. <strong>What repetition is going on?</strong></p>
<p>We can take the mean of facet_comp, grouping by id and facet, again,
which will give us a single score for each facet within each
participant:</p>
<pre class="r"><code>facet_long_4 &lt;- facet_long_3 |&gt;
  group_by(id, facet) |&gt;
  summarise(
    facet_comp = mean(facet_comp, na.rm = TRUE)
  )

print(facet_long_4[1:10, ])</code></pre>
<pre><code>## # A tibble: 10 × 3
## # Groups:   id [4]
##       id facet facet_comp
##    &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;
##  1     1 a           1.75
##  2     1 d           1   
##  3     1 e           1   
##  4     2 a           2.5 
##  5     2 d           3   
##  6     2 e           2.75
##  7     3 a           3   
##  8     3 d           2   
##  9     3 e           3.25
## 10     4 a           3.25</code></pre>
<p>Why does the <code>mean()</code> function work in this way?</p>
<p>Great! Now, we need to move the facets into columns using
<code>pivot_wider()</code>, which will widen the data frame from the long format
we transformed it into.</p>
<p>Then, we can use <code>mutate()</code> to get participant’s overall Neuroticism
composite score by getting the mean of the 3 facet means, per person:</p>
<p>Change this around</p>
<pre class="r"><code>composite_final &lt;- facet_long_4 |&gt;
  pivot_wider(
    id_cols = id, #specifying the id column that identifies each observation
    names_from = facet,
    values_from = facet_comp
  ) |&gt; #can use pipe here to go into the next operation
  group_by(id) |&gt;
  mutate(
    Neuro_comp = rowMeans(across(c(a:e)), na.rm = TRUE)
  ) |&gt;
   #we can change the names to be more informative
   rename(
     Anxiety = a,
     Depression = d,
     Volatility = e
   )

print(composite_final[1:10, ])</code></pre>
<pre><code>## # A tibble: 10 × 5
## # Groups:   id [10]
##       id Anxiety Depression Volatility Neuro_comp
##    &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1     1    1.75       1          1          1.25
##  2     2    2.5        3          2.75       2.75
##  3     3    3          2          3.25       2.75
##  4     4    3.25       2.5        2.75       2.83
##  5     5    3.75       2.25       2          2.67
##  6     6    3          3.25       2.75       3   
##  7     7    2.75       2          1.75       2.17
##  8     8    3.75       3          2          2.92
##  9     9    4          4.25       3.5        3.92
## 10    10    3.5        3.25       3.75       3.5</code></pre>
<div class="puzzle">
<p><strong>You try!</strong></p>
<p>How would I <code>pivot_longer()</code> this final
data frame, with the facet columns and trait column together? Call this <code>long_final</code>.</p>
</div>
<iframe src="https://shelly-cooper.shinyapps.io/32-learnr-app7/" width="100%" height="800" frameborder="0" style="border-radius: 12px; border: 1px solid #ccc;" scrolling="auto">
</iframe>
<p><small>Massive shout out to the Fall 2025 AI Derek Simon for creating this excellent Practice Set!</small></p>
</div>
</div>
</div>
